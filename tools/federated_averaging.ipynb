{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc30e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone github repository\n",
    "!git clone --branch federated https://github.com/AlessandroMaini/federated-learning-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd federated-learning-project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from data.cifar100_loader import get_cifar100_loaders\n",
    "from models.prepare_model import get_frozen_dino_vits16_model\n",
    "from tools.hyperparameter_tuning import run_grid_search\n",
    "from eval import evaluate\n",
    "from train import train\n",
    "from sharding.Imbalance_division import data_division, print_classes_and_counts \n",
    "from FedAvg.averaging import averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8292ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagTest = 1\n",
    "type_sharding = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, train_dataset, test_dataset = get_cifar100_loaders()\n",
    "sharding_dataloaders, cardinality_datasets, sharding_dataloadersTest, cardinality_datasetsTest= data_division(train_dataset,test_dataset, type_sharding, flagTest)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborative_model = get_frozen_dino_vits16_model(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_round = 0\n",
    "num_rounds = 2\n",
    "best_test_acc = 0.0\n",
    "\n",
    "hist_test_loss = []\n",
    "hist_test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(collaborative_model.parameters(), lr=0.01, momentum=0.95, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09913b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative model \n",
    "for round in range(start_round, start_round + num_rounds):\n",
    "    clientsIndex = list(range(100)) \n",
    "    random.shuffle(clientsIndex)\n",
    "    chosenClients = [sharding_dataloaders[i] for i in clientsIndex[:10]] \n",
    "    chosenCardinality = [cardinality_datasets[i] for i in clientsIndex[:10]]\n",
    "\n",
    "    epochs = 4 \n",
    "    averaging(chosenClients, chosenCardinality, collaborative_model, optimizer, device, epochs, criterion)\n",
    "    test_loss, test_acc = evaluate(collaborative_model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    hist_test_loss.append(test_loss)\n",
    "    hist_test_acc.append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {round+1}/{start_round + num_rounds}\")\n",
    "    print(f\"  Test Loss:  {test_loss:.4f} | Test Acc:  {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and test accuracy\n",
    "plt.plot(test_acc, label='Test Accuracy')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "num_epochs = 30\n",
    "\n",
    "hist_test_loss = [[] for _ in range(100)]\n",
    "hist_test_acc = [[] for _ in range(100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76825ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ragionevole solo quanto type_sharding Ã¨ diverso da 1 \n",
    "for client in range(100): \n",
    "    client_model = get_frozen_dino_vits16_model(device,type_sharding)\n",
    "    optimizer = optim.SGD(client_model.parameters(), lr=0.01, momentum=0.95, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):  \n",
    "        train(client_model, sharding_dataloaders[client], optimizer, criterion, device)\n",
    "        scheduler.step()\n",
    "        test_loss, test_acc = evaluate(client_model, sharding_dataloadersTest[client], criterion, device)\n",
    "\n",
    "        hist_test_loss[i].append(test_loss)\n",
    "        hist_test_acc[i].append(test_acc)        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
